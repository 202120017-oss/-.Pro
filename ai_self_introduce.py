# ai_self_introduce.pyì´ (Pro_V3)
# -------------------------------------------------------------
# ğŸ“ ìì†Œì„œ ì–´ë µì§€ ì•Šì•„ìš© pro_V3 â€” ë‹¤êµ­ì–´ + ìŠ¤íƒ€ì¼ ë¹„êµ + ë‹¤ë“¬ê¸°/ë¶„ì„ + PDF/DOCX
# - ì „ë¬¸ ì„œë¹„ìŠ¤í˜• UI (ìƒë‹¨ í—¤ë” + âš™ï¸ íŒì˜¤ë²„ ì„¤ì •)
# - í•œêµ­ì–´ ì¤‘ì‹¬ UI, ê²°ê³¼ ì˜ë¬¸ ë³€í™˜ ì§€ì›
# - ëª¨ë¸: OpenAI / Gemini (ì‚¬ìš©ì API Key)
# - ê¸°ëŠ¥:
#   1) ìŠ¤íƒ€ì¼ ë¹„êµ(2â€“3ê°œ í†¤ ë™ì‹œ ìƒì„±)
#   2) 1â€‘í´ë¦­ PDF/DOCX ë‚´ë³´ë‚´ê¸°(í•œê¸€ í°íŠ¸ ì—…ë¡œë“œ ì§€ì›)
#   3) ë‹¤ë“¬ê¸°/ì¬í†¤ì ìš©, JD í‚¤ì›Œë“œÂ·ê²¹ì¹¨ ê°„ë‹¨ ë¶„ì„
#   4) ì¸ì ì‚¬í•­(ì´ë¦„/ë‚˜ì´/ì„±ë³„/ì£¼ì†Œ) ì…ë ¥ í¬í•¨
#   5) ëª¨ë“  ì…ë ¥ë€ì— ë°˜íˆ¬ëª… ì˜ˆì‹œ(placeholder) ì œê³µ â€” íƒ€ì´í•‘ ì‹œ ìë™ ì‚¬ë¼ì§
# -------------------------------------------------------------
# ì‹¤í–‰
#   pip install -U streamlit openai google-generativeai reportlab python-docx
#   streamlit run app_multilingual_styles_pdf.py

from __future__ import annotations
import os
import io
import re
from typing import List, Dict, Optional

import streamlit as st

# ========== Optional exports ==========
try:
    from docx import Document  # pip install python-docx
    HAS_DOCX = True
except Exception:
    HAS_DOCX = False

# PDF (ReportLab)
try:
    from reportlab.lib.pagesizes import A4
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    from reportlab.lib.units import mm
    HAS_PDF = True
except Exception:
    HAS_PDF = False

# =============================
# Providers (OpenAI / Gemini)
# =============================
class OpenAIProvider:
    def __init__(self, api_key: Optional[str]):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY", "")
        try:
            from openai import OpenAI
            self.client = OpenAI(api_key=self.api_key)
        except Exception as e:
            self.client = None
            st.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def generate(self, messages: List[Dict], model: str, temperature: float, max_tokens: int = 1200) -> str:
        if not self.client:
            raise RuntimeError("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        try:
            resp = self.client.chat.completions.create(
                model=model,
                temperature=temperature,
                max_tokens=max_tokens,
                messages=messages,
            )
            return (resp.choices[0].message.content or "").strip()
        except Exception as e:
            raise RuntimeError(f"OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {e}")

class GeminiProvider:
    def __init__(self, api_key: Optional[str]):
        self.api_key = api_key or os.getenv("GEMINI_API_KEY", "")
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.api_key)
            self.genai = genai
        except Exception as e:
            self.genai = None
            st.error(f"Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def generate(self, messages: List[Dict], model: str, temperature: float, max_tokens: int = 1200) -> str:
        if not self.genai:
            raise RuntimeError("Gemini í´ë¼ì´ì–¸íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        # GeminiëŠ” system/userë¥¼ í•˜ë‚˜ì˜ í”„ë¡¬í”„íŠ¸ë¡œ í•©ì¹¨
        sys_text = "\n\n".join([m["content"] for m in messages if m["role"] == "system"]) or ""
        usr_text = "\n\n".join([m["content"] for m in messages if m["role"] == "user"]) or ""
        prompt = (sys_text + "\n\n" + usr_text).strip()
        try:
            model_obj = self.genai.GenerativeModel(model_name=model)
            resp = model_obj.generate_content(
                prompt,
                generation_config=self.genai.types.GenerationConfig(
                    temperature=temperature,
                    max_output_tokens=max_tokens,
                ),
            )
            if not hasattr(resp, "text") or not resp.text:
                raise RuntimeError("Gemini ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤(ì•ˆì „í•„í„° ë“±).")
            return resp.text.strip()
        except Exception as e:
            raise RuntimeError(f"Gemini í˜¸ì¶œ ì‹¤íŒ¨: {e}")

# =============================
# Prompts (KR/EN)
# =============================
KR_SYSTEM = (
    "ë‹¹ì‹ ì€ ì„¸ê³„ì  ê¸°ì—…ì˜ ì¸ì‚¬ë‹´ë‹¹ì ì¶œì‹  ì»¤ë²„ë ˆí„° ì½”ì¹˜ì…ë‹ˆë‹¤.\n"
    "- í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•©ë‹ˆë‹¤.\n"
    "- ë¶ˆí•„ìš”í•œ ê³¼ì¥ì€ í”¼í•˜ê³  êµ¬ì²´ì  ì„±ê³¼/ì§€í‘œ/ì—­í• ì„ í¬í•¨í•©ë‹ˆë‹¤.\n"
    "- ë¬¸ë‹¨ì€ 3~5ê°œ, ëª©í‘œ ê¸¸ì´ ë‚´ì—ì„œ êµ¬ì„±í•©ë‹ˆë‹¤.\n"
    "- ì—…ê³„ ìš©ì–´ëŠ” ì •í™•íˆ ì‚¬ìš©í•©ë‹ˆë‹¤."
)
EN_SYSTEM = (
    "You are a world-class cover letter coach and former recruiter.\n"
    "- Write concise, professional English.\n"
    "- Avoid fluff; include concrete achievements, metrics, and roles.\n"
    "- Aim for 3â€“5 paragraphs within target length.\n"
    "- Use industry-appropriate terminology."
)

KR_TONES: Dict[str, str] = {
    "ì •ì¤‘í•œ": "í†¤ì€ ì •ì¤‘í•˜ê³  ì‹ ë¢°ê° ìˆê²Œ ìœ ì§€í•©ë‹ˆë‹¤.",
    "ì—´ì •ì ì¸": "í†¤ì€ ì—´ì •ì ì´ê³  ì¶”ì§„ë ¥ì„ ê°•ì¡°í•©ë‹ˆë‹¤.",
    "ë¶„ì„ì ì¸": "í†¤ì€ ë…¼ë¦¬ì ì´ê³  ë¶„ì„ì ìœ¼ë¡œ, ë°ì´í„°ì™€ ê·¼ê±°ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.",
    "ë‹´ë°±í•œ": "í†¤ì€ ë‹´ë°±í•˜ê³  ê°„ê²°í•˜ê²Œ í•µì‹¬ë§Œ ì „ë‹¬í•©ë‹ˆë‹¤.",
}
EN_TONES: Dict[str, str] = {
    "Polite": "Maintain a polite, trustworthy tone.",
    "Energetic": "Use a passionate, high-drive tone.",
    "Analytical": "Use a logical, analytical tone with data and evidence.",
    "Concise": "Be succinct and straight to the point.",
}

# ë©”ì‹œì§€ ë¹Œë” â€” ì¸ì ì‚¬í•­ í¬í•¨
def build_draft_messages(lang_code: str, company: str, job_title: str, jd_text: str, resume_text: str,
                         tone_label: str, extra_reqs: str, target_len: int,
                         name: str, age: str, gender: str, address: str) -> List[Dict]:
    personal = f"[ì¸ì ì‚¬í•­] ì´ë¦„:{name} / ë‚˜ì´:{age} / ì„±ë³„:{gender} / ì£¼ì†Œ:{address}\n".strip()
    if lang_code == "KR":
        system = KR_SYSTEM
        tone_instr = KR_TONES.get(tone_label, "í†¤ì€ ì •ì¤‘í•˜ê³  ëª…í™•í•©ë‹ˆë‹¤.")
        user = (
            f"[íšŒì‚¬] {company}\n[ì§ë¬´] {job_title}\n{personal}\n\n"
            f"[ì±„ìš©ê³µê³ ]\n{jd_text}\n\n"
            f"[ì´ë ¥/ê²½í—˜]\n{resume_text}\n\n"
            f"[í†¤/ìš”ì²­] {tone_instr} {extra_reqs}\n"
            f"[ëª©í‘œ ê¸¸ì´] ì•½ {target_len}ì"
        )
    else:
        system = EN_SYSTEM
        tone_instr = EN_TONES.get(tone_label, "Maintain a professional tone.")
        user = (
            f"[Company] {company}\n[Position] {job_title}\n[Personal] Name:{name} / Age:{age} / Gender:{gender} / Address:{address}\n\n"
            f"[Job Description]\n{jd_text}\n\n"
            f"[Resume Highlights]\n{resume_text}\n\n"
            f"[Tone/Guidance] {tone_instr} {extra_reqs}\n"
            f"[Target Length] ~{target_len} words"
        )
    return [
        {"role": "system", "content": system},
        {"role": "user", "content": user},
    ]

def build_refine_messages(lang_code: str, base_text: str, tone: str, target_len: int) -> List[Dict]:
    if lang_code == "KR":
        sys = "ë„ˆëŠ” ì „ë¬¸ ì—ë””í„°ì´ì HR ì»¨ì„¤í„´íŠ¸ë‹¤. ì¤‘ë³µì„ ì¤„ì´ê³  êµ¬ì¡°ë¥¼ ë˜ë ·í•˜ê²Œ ë‹¤ë“¬ì–´ë¼."
        user = (
            f"ë‹¤ìŒ ìê¸°ì†Œê°œì„œë¥¼ {tone} í†¤ì— ë§ì¶° ë‹¤ë“¬ê³ , ë¶ˆí•„ìš”í•œ êµ°ë”ë”ê¸°ë¥¼ ì œê±°í•˜ê³ , ë¬¸ë‹¨ êµ¬ì„±ì„ ì„ ëª…íˆ í•˜ì„¸ìš”.\n"
            f"ëª©í‘œ ê¸¸ì´ëŠ” ì•½ {target_len}ìì…ë‹ˆë‹¤.\n\n[ì›ë¬¸]\n{base_text}"
        )
    else:
        sys = "You are an expert editor and HR consultant. Tighten structure, reduce redundancy."
        user = (
            f"Refine the following cover letter into a {tone} tone; reduce fluff and ensure clear paragraphing.\n"
            f"Target length: ~{target_len} words.\n\n[Original]\n{base_text}"
        )
    return [
        {"role": "system", "content": sys},
        {"role": "user", "content": user},
    ]

def build_keywords_messages(lang_code: str, jd_text: str, essay: str) -> List[Dict]:
    if lang_code == "KR":
        sys = "ë„ˆëŠ” ì±„ìš©ë‹´ë‹¹ìë‹¤. JD-ì‘ë‹µ ë§¤ì¹­ í’ˆì§ˆì„ í‚¤ì›Œë“œ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•œë‹¤."
        user = (
            "ë‹¤ìŒ JDì™€ ìê¸°ì†Œê°œì„œë¥¼ ë³´ê³ , ê¸°ì—…ì´ ì¤‘ìš”í•˜ê²Œ ë³´ëŠ” í•µì‹¬ í‚¤ì›Œë“œ 12ê°œ ë‚´ì™¸ë¥¼ í•œêµ­ì–´ë¡œ ì¶”ì¶œí•˜ê³ , "
            "ê° í‚¤ì›Œë“œì˜ ë°˜ì˜ ì—¬ë¶€(ìˆìŒ/ì•½í•¨/ì—†ìŒ)ë¥¼ í‘œì‹œí•´ í‘œ í˜•íƒœì˜ í…ìŠ¤íŠ¸ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n\n"
            f"[JD]\n{jd_text}\n\n[ìê¸°ì†Œê°œì„œ]\n{essay}"
        )
    else:
        sys = "You are a recruiter. Evaluate JD-response alignment by keywords."
        user = (
            "From the JD and cover letter, extract ~12 critical keywords and mark for each whether it's Present/Weak/Absent, "
            "as a simple text table.\n\n"
            f"[JD]\n{jd_text}\n\n[Cover Letter]\n{essay}"
        )
    return [
        {"role": "system", "content": sys},
        {"role": "user", "content": user},
    ]

# ì˜ë¬¸ ë³€í™˜ ë©”ì‹œì§€
def build_translate_to_en_messages(text_kr: str) -> List[Dict]:
    sys = "You are a professional translator. Translate the Korean cover letter to natural, professional English while preserving structure and intent."
    usr = f"Translate the following Korean cover letter to English:\n\n{text_kr}"
    return [{"role": "system", "content": sys}, {"role": "user", "content": usr}]

# ============== Simple coverage ==============
def naive_coverage(jd_text: str, essay: str) -> Dict[str, float]:
    norm = lambda s: re.sub(r"[^0-9A-Za-zê°€-í£ ]+", " ", s).lower()
    jd_tokens = [t for t in norm(jd_text).split() if len(t) >= 2]
    es_tokens = [t for t in norm(essay).split() if len(t) >= 2]
    if not jd_tokens or not es_tokens:
        return {"overlap_ratio": 0.0, "jd_vocab": 0, "match_count": 0}
    jd_set, es_set = set(jd_tokens), set(es_tokens)
    match = len(jd_set & es_set)
    return {
        "overlap_ratio": round(match / max(1, len(jd_set)), 3),
        "jd_vocab": len(jd_set),
        "match_count": match,
    }

# =============================
# UI â€” ì „ë¬¸ ì„œë¹„ìŠ¤ ìŠ¤íƒ€ì¼
# =============================
st.set_page_config(page_title="ìì†Œì„œ ì–´ë µì§€ ì•Šì•„ìš© pro_V3", page_icon="ğŸ“", layout="wide")

st.markdown(
    """
    <style>
      .block-container {max-width: 1200px;}
      .app-header {display:flex; align-items:center; justify-content:space-between; padding:8px 4px 16px 4px; border-bottom:1px solid #eee;}
      .title {font-size: 26px; font-weight: 700; letter-spacing: -0.3px;}
      .subtitle {color:#666; font-size:13px;}
      .stTabs [data-baseweb=tab] {height: 48px; padding-top: 10px; font-weight:600;}
      footer {visibility: hidden;}
      .hint {color:#6b7280; font-size:12px;}
    </style>
    """,
    unsafe_allow_html=True,
)

# ìƒë‹¨ í—¤ë” + âš™ï¸ ì„¤ì • íŒì˜¤ë²„
left, right = st.columns([7, 1])
with left:
    st.markdown('<div class="app-header"><div><div class="title">ğŸ“ ìì†Œì„œ ì–´ë µì§€ ì•Šì•„ìš© pro_V3</div><div class="subtitle">ë‹¤êµ­ì–´ ìƒì„± â€¢ ìŠ¤íƒ€ì¼ ë¹„êµ â€¢ ë‹¤ë“¬ê¸°/ë¶„ì„ â€¢ PDF/DOCX</div></div></div>', unsafe_allow_html=True)
with right:
    pop = st.popover("âš™ï¸ ì„¤ì •", use_container_width=True)
    with pop:
        st.markdown("**ëª¨ë¸ ë° ë‚´ë³´ë‚´ê¸° ì„¤ì •**")
        provider_name = st.selectbox("ëª¨ë¸ ì œê³µì", ["OpenAI", "Gemini"], index=0)
        if provider_name == "OpenAI":
            openai_key = st.text_input("OpenAI API Key", type="password", value=os.getenv("OPENAI_API_KEY", ""))
            model = st.text_input("OpenAI ëª¨ë¸", value="gpt-4o-mini")
            api_key = openai_key
        else:
            gemini_key = st.text_input("Gemini API Key", type="password", value=os.getenv("GEMINI_API_KEY", ""))
            model = st.text_input("Gemini ëª¨ë¸", value="gemini-1.5-flash")
            api_key = gemini_key
        temperature = st.slider("ì°½ì˜ì„± (Temperature)", 0.0, 1.2, 0.7, 0.05)
        st.markdown("---")
        # ì–¸ì–´/í†¤/ê¸¸ì´ë„ ì„¤ì •ìœ¼ë¡œ ì´ë™
        language = st.selectbox("ì‘ì„± ì–¸ì–´", ["í•œêµ­ì–´ (KR)", "English (EN)"])
        lang_code = "KR" if language.startswith("í•œêµ­ì–´") else "EN"
        tone_options = list(KR_TONES.keys()) if lang_code == "KR" else list(EN_TONES.keys())
        default_tones = ["ì •ì¤‘í•œ", "ë¶„ì„ì ì¸"] if lang_code == "KR" else ["Polite", "Analytical"]
        selected_tones = st.multiselect("ë¹„êµí•  í†¤ (2â€“3ê°œ ê¶Œì¥)", options=tone_options, default=default_tones)
        target_len = st.slider("ëª©í‘œ ê¸¸ì´ (KR:ì / EN:ë‹¨ì–´)" if lang_code=="KR" else "Target length (words)",
                               min_value=400 if lang_code=="KR" else 150,
                               max_value=1100 if lang_code=="KR" else 450,
                               value=800 if lang_code=="KR" else 280,
                               step=50 if lang_code=="KR" else 10)
        st.markdown("---")
        font_uploader = st.file_uploader("(ì„ íƒ) PDFìš© í•œê¸€ í°íŠ¸ ì—…ë¡œë“œ (TTF/OTF)", type=["ttf", "otf"])
        font_bytes = font_uploader.read() if font_uploader else None
        font_name = font_uploader.name if font_uploader else None
        st.caption("í•œêµ­ì–´ PDFê°€ ê¹¨ì§€ë©´ í°íŠ¸ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (ì˜ˆ: NotoSansKR).")

# ì…ë ¥ â€” ì¸ì ì‚¬í•­ + ê¸°ë³¸ ì •ë³´ (ë°˜íˆ¬ëª… placeholder)
colP, colJ = st.columns(2)
with colP:
    st.subheader("ì¸ì ì‚¬í•­")
    name = st.text_input("ì´ë¦„", placeholder="ì˜ˆ) ê¹€ì¤€í˜¸")
    age = st.text_input("ë‚˜ì´", placeholder="ì˜ˆ) 30")
    gender = st.text_input("ì„±ë³„", placeholder="ì˜ˆ) ë‚¨ / ì—¬")
    address = st.text_input("ì£¼ì†Œ", placeholder="ì˜ˆ) ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ â€¦")
with colJ:
    st.subheader("ì§€ì› ì •ë³´")
    company = st.text_input("íšŒì‚¬ / Company", placeholder="ì˜ˆ) ì¹´ì¹´ì˜¤ì—”í„°í”„ë¼ì´ì¦ˆ (Kakao Enterprise)")
    job_title = st.text_input("ì§ë¬´ / Position", placeholder="ì˜ˆ) ë°ì´í„° ë¶„ì„ê°€ (Data Analyst)")

jd_text = st.text_area(
    "ì±„ìš©ê³µê³  / Job Description",
    height=160,
    placeholder=(
        "ì˜ˆ) ì£¼ìš”ì—…ë¬´: ë°ì´í„° ê¸°ë°˜ ì œí’ˆ ê°œì„ , ëŒ€ì‹œë³´ë“œ êµ¬ì¶•, ì‹¤í—˜ ì„¤ê³„/ë¶„ì„\n"
        "ìê²©ìš”ê±´: SQL ëŠ¥ìˆ™, Python ë¶„ì„ ê²½í—˜, A/B í…ŒìŠ¤íŠ¸ ì´í•´, ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥\n"
        "ìš°ëŒ€ì‚¬í•­: ëŒ€ê·œëª¨ ë¡œê·¸ ë¶„ì„ ê²½í—˜, í´ë¼ìš°ë“œ ë¶„ì„ ë„êµ¬ ê²½í—˜"
    ),
)

resume_text = st.text_area(
    "ì´ë ¥ ì£¼ìš” ë‚´ìš© / Resume Highlights",
    height=160,
    placeholder=(
        "ì˜ˆ) ì „ììƒê±°ë˜ ë°ì´í„° ë¶„ì„ 2ë…„: ì „í™˜ìœ¨ +12% ê°œì„ , ë¦¬í…ì…˜ +8% í–¥ìƒ\n"
        "SQL/BigQuery, Python(pandas, scikit-learn), ì‹¤í—˜ ì„¤ê³„ ê²½í—˜\n"
        "ë§ˆì¼€íŒ…/ê°œë°œê³¼ í˜‘ì—…í•˜ì—¬ ì£¼ê°„ BI ëŒ€ì‹œë³´ë“œ ìš´ì˜"
    ),
)

extra_reqs = st.text_area(
    "ì¶”ê°€ ê°€ì´ë“œ (ì„ íƒ)", height=90,
    placeholder="ì˜ˆ) ì„±ê³¼ëŠ” ìˆ«ìë¡œ, í˜‘ì—…/ë¦¬ë”ì‹­ 1ê°œ ë¬¸ë‹¨ ê°•ì¡°, 800ì Â±15%",
)

# íƒ­: 1) ìƒì„±/ë‚´ë³´ë‚´ê¸°  2) ë‹¤ë“¬ê¸°/ë¶„ì„
main_tabs = st.tabs(["âœï¸ ìƒì„± & ë‚´ë³´ë‚´ê¸°", "ğŸ› ï¸ ë‹¤ë“¬ê¸° & ë¶„ì„"])

# ====== íƒ­ 1: ìƒì„± & ë‚´ë³´ë‚´ê¸° ======
with main_tabs[0]:
    st.subheader("ìŠ¤íƒ€ì¼ ë¹„êµ ìƒì„±")

    provider = OpenAIProvider(api_key) if 'provider_name' in locals() and provider_name == "OpenAI" else GeminiProvider(api_key if 'api_key' in locals() else None)
    disabled = ('api_key' not in locals()) or (not api_key)
    if disabled:
        st.info("ğŸ”‘ ìš°ì¸¡ ìƒë‹¨ âš™ï¸ì—ì„œ API Keyì™€ ëª¨ë¸ì„ ì„¤ì •í•˜ì„¸ìš”.")

    go = st.button("ë³€í˜• ìƒì„±", disabled=disabled, use_container_width=True)

    gen_results: Dict[str, str] = {}
    if go:
        if not selected_tones:
            st.warning("ë¹„êµí•  í†¤ì„ 1ê°œ ì´ìƒ ì„ íƒí•˜ì„¸ìš”.")
        elif not (company and job_title and jd_text and resume_text and name):
            st.warning("íšŒì‚¬/ì§ë¬´/JD/ì´ë ¥ê³¼ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ìƒì„± ì¤‘â€¦"):
                for tone in selected_tones:
                    msgs = build_draft_messages(lang_code, company, job_title, jd_text, resume_text, tone, extra_reqs, target_len, name, age, gender, address)
                    try:
                        txt = provider.generate(msgs, model=model, temperature=temperature, max_tokens=1400)
                    except Exception as e:
                        st.error(str(e))
                        txt = "(ìƒì„± ì‹¤íŒ¨)"
                    gen_results[tone] = txt or "(ìƒì„± ì‹¤íŒ¨)"

    if gen_results:
        cols = st.columns(len(gen_results))
        for i, (tone, text) in enumerate(gen_results.items()):
            with cols[i]:
                st.markdown(f"**{tone}**")
                st.text_area("", value=text, height=360, key=f"out_{tone}")

        st.markdown("---")
        st.subheader("ë‚´ë³´ë‚´ê¸° / ì˜ë¬¸ ë³€í™˜")
        exp_cols = st.columns(len(gen_results))
        for i, (tone, text) in enumerate(gen_results.items()):
            with exp_cols[i]:
                label = f"{company} â€” {job_title} ({tone})"
                # PDF
                try:
                    pdf_bytes = build_pdf_bytes(text, label, "KR" if lang_code=="KR" else "EN", font_bytes if 'font_bytes' in locals() else None, font_name if 'font_name' in locals() else None)
                    st.download_button("â¬‡ï¸ PDF", data=pdf_bytes, file_name=f"{company}_{job_title}_{tone}.pdf")
                except Exception as e:
                    st.error(f"PDF ì‹¤íŒ¨: {e}")
                # DOCX
                if HAS_DOCX:
                    try:
                        buf = io.BytesIO()
                        doc = Document()
                        doc.add_heading(label, level=1)
                        for para in text.split("\n\n"):
                            doc.add_paragraph(para)
                        doc.save(buf)
                        buf.seek(0)
                        st.download_button("â¬‡ï¸ DOCX", data=buf.getvalue(), file_name=f"{company}_{job_title}_{tone}.docx")
                    except Exception as e:
                        st.error(f"DOCX ì‹¤íŒ¨: {e}")
                else:
                    st.caption("DOCX: `pip install python-docx` í•„ìš”")

        # í†µí•© PDF
        if st.checkbox("ëª¨ë“  ë²„ì „ì„ í•˜ë‚˜ì˜ PDFë¡œ ë¬¶ê¸°"):
            all_text = "\n\n\n".join([f"[{tone}]\n\n{text}" for tone, text in gen_results.items()])
            try:
                combined = build_pdf_bytes(all_text, f"{company} â€” {job_title} (All styles)", "KR" if lang_code=="KR" else "EN", font_bytes if 'font_bytes' in locals() else None, font_name if 'font_name' in locals() else None)
                st.download_button("â¬‡ï¸ í†µí•© PDF", data=combined, file_name=f"{company}_{job_title}_ALL.pdf")
            except Exception as e:
                st.error(f"í†µí•© PDF ì‹¤íŒ¨: {e}")

        # ì˜ë¬¸ ë³€í™˜(ê° ë²„ì „)
        st.markdown("---")
        st.subheader("ìƒì„±ë³¸ ì˜ë¬¸ ë³€í™˜")
        trans_cols = st.columns(len(gen_results))
        for i, (tone, text) in enumerate(gen_results.items()):
            with trans_cols[i]:
                if st.button(f"ì˜ë¬¸ìœ¼ë¡œ ë³€í™˜ ({tone})", key=f"tr_btn_{tone}", use_container_width=True, disabled=disabled):
                    provider_tr = OpenAIProvider(api_key) if provider_name == "OpenAI" else GeminiProvider(api_key)
                    with st.spinner("ì˜ë¬¸ ë³€í™˜ ì¤‘â€¦"):
                        try:
                            msgs_tr = build_translate_to_en_messages(text)
                            en_text = provider_tr.generate(msgs_tr, model=model, temperature=0.3, max_tokens=1400)
                            st.text_area("ì˜ë¬¸ ê²°ê³¼", value=en_text, height=300, key=f"out_en_{tone}")
                        except Exception as e:
                            st.error(str(e))

# ====== íƒ­ 2: ë‹¤ë“¬ê¸° & ë¶„ì„ ======
with main_tabs[1]:
    st.subheader("ë‹¤ë“¬ê¸° / ì¬í†¤ ì ìš©")
    st.markdown("<span class='hint'>ì˜ˆì‹œ: ì•„ë˜ì— ê¸°ì¡´ ìê¸°ì†Œê°œì„œ ì´ˆì•ˆì„ ë¶™ì—¬ë„£ê³  í†¤ê³¼ ê¸¸ì´ë¥¼ ì¡°ì ˆí•´ ë‹¤ë“¬ì„ ìˆ˜ ìˆì–´ìš”.</span>", unsafe_allow_html=True)

    base_text = st.text_area("ì›ë¬¸ ë¶™ì—¬ë„£ê¸°", height=220, placeholder="ì˜ˆ) ì €ëŠ” ì „ììƒê±°ë˜ ë°ì´í„° ë¶„ì„ê°€ë¡œì„œ 2ë…„ê°„ ì „í™˜ìœ¨ ê°œì„ ê³¼ ë¦¬í…ì…˜ í–¥ìƒì„ ì´ëŒì—ˆìŠµë‹ˆë‹¤â€¦")

    colR1, colR2, colR3 = st.columns([2, 1, 1])
    with colR1:
        refine_tone_opts = (tone_options)
        refine_tone = st.selectbox("í†¤ ì„ íƒ", options=refine_tone_opts, index=0)
    with colR2:
        ref_len = st.number_input("ëª©í‘œ ê¸¸ì´", value=800 if 'target_len' in locals() and lang_code=="KR" else 280, min_value=200, max_value=2000, step=50)
    with colR3:
        btn_refine = st.button("ë‹¤ë“¬ê¸° ì‹¤í–‰", disabled=('api_key' not in locals()) or (not api_key), use_container_width=True)

    refined_text = ""
    if btn_refine:
        if not base_text.strip():
            st.warning("ì›ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            provider2 = OpenAIProvider(api_key) if provider_name == "OpenAI" else GeminiProvider(api_key)
            msgs = build_refine_messages(lang_code, base_text, refine_tone, int(ref_len))
            with st.spinner("ë‹¤ë“¬ëŠ” ì¤‘â€¦"):
                try:
                    refined_text = provider2.generate(msgs, model=model, temperature=0.6, max_tokens=1200)
                except Exception as e:
                    st.error(str(e))
                    refined_text = "(ë‹¤ë“¬ê¸° ì‹¤íŒ¨)"
    st.text_area("ë‹¤ë“¬ì€ ê²°ê³¼", value=refined_text, height=220, key="refined_view")

    st.markdown("---")
    st.subheader("ë¶„ì„: í‚¤ì›Œë“œ & ê²¹ì¹¨")
    st.markdown("<span class='hint'>ì˜ˆì‹œ: JDì™€ ë‹¤ë“¬ì€ ê²°ê³¼ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•µì‹¬ í‚¤ì›Œë“œì™€ ê²¹ì¹¨ ë¹„ìœ¨ì„ í™•ì¸í•©ë‹ˆë‹¤.</span>", unsafe_allow_html=True)

    colK1, colK2 = st.columns(2)
    with colK1:
        analysis_src = st.text_area("ë¶„ì„ ëŒ€ìƒ ë³¸ë¬¸", value=refined_text, height=180, placeholder="ì˜ˆ) ë‹¤ë“¬ì€ ê²°ê³¼ë¥¼ ì—¬ê¸°ì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”")
    with colK2:
        btn_kw = st.button("í‚¤ì›Œë“œ ì¶”ì¶œ ë° ê²¹ì¹¨ ê³„ì‚°", disabled=('api_key' not in locals()) or (not api_key), use_container_width=True)
        analysis_out = st.empty()

    if btn_kw:
        if not (jd_text and (analysis_src or refined_text)):
            analysis_out.warning("JDì™€ ë¶„ì„ ë³¸ë¬¸ì„ í™•ì¸í•˜ì„¸ìš”.")
        else:
            provider3 = OpenAIProvider(api_key) if provider_name == "OpenAI" else GeminiProvider(api_key)
            msgs = build_keywords_messages(lang_code, jd_text, analysis_src or refined_text)
            with st.spinner("ë¶„ì„ ì¤‘â€¦"):
                # LLM keywords
                kw_text = ""
                try:
                    kw_text = provider3.generate(msgs, model=model, temperature=0.2, max_tokens=800)
                except Exception as e:
                    analysis_out.error(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                # Naive coverage
                try:
                    cov = naive_coverage(jd_text, analysis_src or refined_text)
                    st.metric("JD ì–´íœ˜ ê²¹ì¹¨ ë¹„ìœ¨", f"{cov['overlap_ratio']*100:.1f}%")
                    st.caption(f"JD ì–´íœ˜ìˆ˜: {cov['jd_vocab']} / ë§¤ì¹˜: {cov['match_count']}")
                except Exception as e:
                    st.error(f"ê²¹ì¹¨ ê³„ì‚° ì‹¤íŒ¨: {e}")
            st.text_area("í‚¤ì›Œë“œ í‰ê°€ (LLM)", value=kw_text, height=180)

st.divider()
st.markdown("<small>Tip: ìš°ì¸¡ ìƒë‹¨ âš™ï¸ì—ì„œ ì–¸ì–´/í†¤/ê¸¸ì´ê¹Œì§€ í•œ ë²ˆì— ì„¤ì •í•˜ê³ , íƒ­ë³„ ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ ë°”ë¡œ ìƒì„±í•´ ë³´ì„¸ìš”.</small>", unsafe_allow_html=True)
